<!DOCTYPE html>
<html lang="uz">
<head>
<meta charset="UTF-8">
<title>Test qidiruv</title>
<style>
  body { font-family: Arial; padding: 20px; }
  #search { width: 100%; padding: 8px; margin-bottom: 10px; }
  .question { margin-bottom: 15px; white-space: pre-wrap; }
  mark { background: yellow; }
</style>
</head>
<body>

<h3>Testlar</h3>

<input id="search" type="text" placeholder="Qidir...">

<hr>

<!-- Savollarni shu yerga joylang -->
<div id="data" style="display:none;">
1.Axborot izlash jarayonida qanday asosiy bosqichlar mavjud?
#a) Maqsadni belgilash
b) Axborotni tahlil qilish
c) Izlash strategiyasini ishlab chiqish
d) Natijalarni baholash
2.Qaysi metod axborotni ajratib olishda eng koâ€˜p qoâ€˜llaniladi?
#a) Tahliliy metod
b) Statistik metod
c) Eksperimental metod
d) Tizimli metod
3.Axborotni izlashda â€œboâ€˜shliqlarâ€ (gaps) nima maâ€™noni anglatadi?
a) Mavjud boâ€˜lgan axborotning kamligi
b) Izlanish jarayonida yuzaga keladigan savollar
#c) Ehtiyojlar va mavjud axborot oâ€˜rtasidagi farq
d) Yangi axborot manbalarining ochilishi
4.Qaysi axborot manbai eng ishonchli hisoblanadi?
a) Shaxsiy bloglar
#b) Ilmiy maqolalar
c) Ijtimoiy tarmoqlar
d) Yangiliklar saytlar
5.Axborotni ajratib olishda â€œmaâ€™lumotlarni tozalashâ€ jarayoni nima?
a) Axborotni yangi formatga oâ€˜tkazish
#b) Keraksiz yoki notoâ€˜gâ€˜ri maâ€™lumotlarni olib tashlash
c) Axborotni tahlil qilish
d) Axborotni saqlash jarayoni
6.Qaysi algoritm axborot izlashda tez-tez qoâ€˜llaniladi?
a) Quick Sort
b) Dijkstra
#c) PageRank
d) K-means
7.Axborotlarni ajratib olishda â€œnatural language processingâ€ (NLP) nima?
a) Axborotni kodlash jarayoni
#b) Tilni tushunish va tahlil qilish jarayoni
c) Axborotni vizualizatsiya qilish
d) Axborotni saqlash jarayoni
8.Qaysi usul axborotlarni izlashda eng samarali hisoblanadi?
#a) Klasifikatsiya
b) Klasterlash
c) Regressiya
d) Qayta oâ€˜qitish
9.Qanday axborot izlash tizimlari mavjud?
a) Qidiruv tizimlari
b) Ma'lumotlar bazalari
c) Ijtimoiy tarmoqlar
#d) Barchasi
10.Axborotni ajratib olish jarayoni qanday asosiy nazoratlar bilan amalga oshiriladi?
a) Mavjud bo'lgan axborotni yangilash
b) Qayta ishlash va saqlash
#c) Tahlil va baholash 
d) Ijtimoiy tahlil
11. Mantiqiy qidiruv nima?
A) Tasodifiy maâ€™lumot izlash
B) Kalit soâ€˜zsiz qidiruv
# C) Mantiqiy operatorlar yordamida aniq maâ€™lumot izlash
D) Faqat matnni oâ€˜qish jarayoni
12. Qaysi operator mantiqiy qidiruvda va maâ€™nosini bildiradi?
A) OR
B) NOT
#C) AND
D) IF
13. AND operatori qanday natija beradi?
A) Soâ€˜zlardan bittasi qatnashgan natijalarni
# B) Barcha soâ€˜zlar qatnashgan natijalarni
C) Keraksiz natijalarni
D) Faqat rasmli natijalarni
14. OR operatorining vazifasi nima?
A) Soâ€˜zlarni inkor qilish
# B) Soâ€˜zlardan kamida bittasi mavjud boâ€˜lgan natijalarni topish
C) Qidiruvni toâ€˜xtatish
D) Qidiruvni cheklash
15. NOT operatori nimaga xizmat qiladi?
A) Natijalarni kengaytirish
B) Qidiruvni tezlashtirish
# C) Maâ€™lum soâ€˜zni chiqarib tashlash
D) Rasm qidirish
16. Qaysi yozuv mantiqiy qidiruvga misol boâ€˜la oladi?
A) kompyuter internet
# B) kompyuter AND internet
C) kompyuter, internet
D) kompyuter + internet
17. Mantiqiy qidiruvning asosiy maqsadi nima?
A) Koâ€˜proq natija olish
B) Internet tezligini oshirish
# C) Aniq va kerakli maâ€™lumotni topish
D) Fayllarni yuklash
18. Qaysi operator eng koâ€˜p natija beradi?
A) AND
B) NOT
#C) OR
D) NONE
19. Mantiqiy qidiruv qayerlarda qoâ€˜llaniladi?
A) Faqat darsliklarda
B) Faqat dasturlashda
# C) Qidiruv tizimlarida va maâ€™lumotlar bazalarida
D) Faqat oâ€˜yinlarda
20. Mantiqiy qidiruv qaysi fan bilan chambarchas bogâ€˜liq?
A) Biologiya
B) Tarix
# C) Informatika
D) Adabiyot
21. Lugâ€˜atlar uchun qidiruv strukturalari nima maqsadda ishlatiladi?
#a) Maâ€™lumotlarni tez va samarali qidirish uchun
b) Fayllarni oâ€˜chirish uchun
c) Rasmlarni saqlash uchun
d) Videolarni tahrirlash uchun
22. Wildcard (niqob) soâ€˜rovlar qanday belgilardan foydalanadi?
#a) # va ? kabi maxsus belgilar
b) Faqat raqamlar
c) Faqat katta harflar
d) Faqat kichik harflar
23. K-gram indekslar qaysi vazifani bajaradi?
#a) Wildcard soâ€˜rovlarni tezroq qayta ishlash uchun ishlatiladi
b) Fayllarni arxivlash uchun
c) Parollarni shifrlash uchun
d) Audio fayllarni oâ€™zgartirish uchun
24. Imlo xatolarini tuzatish (spelling correction) ning asosiy maqsadi nima?
#a) Notoâ€˜gâ€˜ri yozilgan soâ€˜zlarni toâ€˜gâ€˜rilash
b) Matnni tarjima qilish
c) Matnni chop etish
d) Matnni oâ€˜chirish
25. Edit distance (tahrirlash masofasi) nimani oâ€˜lchaydi?
#a) Ikki soâ€˜z orasidagi farqni (qancha oâ€˜zgarish kerakligini)
b) Fayl hajmini
c) Internet tezligini
d) Kompyuter xotirasini
26. Kontekstga bogâ€˜liq imlo tuzatish (context sensitive spelling correction) qachon muhim?
#a) Soâ€˜zning maâ€™nosi kontekstga bogâ€˜liq boâ€˜lganda
b) Fayl yuklanayotganda
c) Dastur oâ€˜rnatilayotganda
d) Kompyuter oâ€˜chirilganda
27. K-gram indekslari imlo tuzatishda qanday yordam beradi?
#a) Oâ€˜xshash soâ€˜zlarni topish orqali toâ€˜gâ€˜ri variantlarni taklif qiladi
b) Fayllarni nusxalaydi
c) Internetga ulanadi
d) Ekranni tozalaydi
28. Fonetik tuzatish (phonetic correction) nimaga asoslangan?
#a) Soâ€˜zlarning tovushiga (talaffuziga)
b) Soâ€˜zlarning rangiga
c) Soâ€˜zlarning uzunligiga
d) Soâ€˜zlarning shakliga
29. Umumiy wildcard soâ€˜rovlar (general wildcard queries) qanday soâ€˜rovlarni qamrab oladi?
#a) Soâ€˜zning istalgan joyida niqob belgisi boâ€˜lishi mumkin boâ€˜lgan soâ€˜rovlar
b) Faqat boshida # belgisi boâ€˜lgan soâ€˜rovlar
c) Faqat oxirida # belgisi boâ€˜lgan soâ€˜rovlar
d) Hech qanday belgi boâ€˜lmagan soâ€˜rovlar
30. Imlo tuzatishni amalga oshirishda (implementing spelling correction) qaysi yondashuv ishlatiladi?
#a) Lugâ€˜at va algoritm asosida eng yaqin toâ€˜gâ€˜ri soâ€˜zni topish
b) Tasodifiy soâ€˜z tanlash
c) Foydalanuvchidan soâ€˜rash
d) Hech narsa qilmaslik
31. Vektor makon nima deb ataladi?
# A. Vektorlar toâ€˜plami boâ€˜lib, unda qoâ€˜shish va songa koâ€˜paytirish amallari aniqlangan va aksiomalarga boâ€˜ysunadi
B. Har qanday sonlar toâ€˜plami
C. Amallarsiz funksiyalar toâ€˜plami
D. Tekislikdagi geometrik shakl
32. Qachon vektor makon muddatli (chekli oâ€˜lchamli) deb ataladi?
# A. Agar u chekli bazisga ega boâ€˜lsa
B. Agar unda cheksiz koâ€˜p vektorlar boâ€˜lsa
C. Agar barcha vektorlar nolga teng boâ€˜lsa
D. Agar u tekislikda berilgan boâ€˜lsa
33. Vektor makonning oâ€˜lchami nima?
# A. Bazisdagi vektorlar soni
B. Vektor uzunligi
C. Koordinataning eng katta qiymati
D. Makondagi barcha vektorlar soni
34. Vektor makonning bazisi nima?
# A. Chiziqli bogâ€˜lanmagan vektorlar tizimi boâ€˜lib, ular orqali makondagi barcha vektorlar ifodalanadi
B. Har qanday vektorlar tizimi
C. Ortogonal vektorlar toâ€˜plami
D. Nol vektorlar toâ€˜plami
35. Vaznli modelda vazn (vazn koeffitsienti) nimani bildiradi?
# A. Vektor komponentasining muhimlik darajasini koâ€˜rsatuvchi son
B. Makon oâ€˜lchamini
C. Vektor uzunligini
D. Bazis vektorlar sonini
36. Vaznli skalyar koâ€˜paytmada vaznlarga odatda qanday shart qoâ€˜yiladi?
# A. Barcha vaznlar musbat boâ€˜lishi kerak
B. Barcha vaznlar nolga teng boâ€˜lishi kerak
C. Vaznlar manfiy boâ€˜lishi shart
D. Vaznlar hisoblashga taâ€™sir qilmaydi
37. Vaznlar vektor makon geometriyasiga qanday taâ€™sir qiladi?
# A. Uzunliklar va burchaklarning oâ€˜zgarishiga olib keladi
B. Makon oâ€˜lchamini kamaytiradi
C. Bazisni yoâ€˜q qiladi
D. Vektorlarni nolga aylantiradi
38. Vaznli modellar nima uchun ishlatiladi?
# A. Vektor komponentalarining turli darajadagi muhimligini hisobga olish uchun
B. Makon oâ€˜lchamini kamaytirish uchun
C. Bazisni olib tashlash uchun
D. Vektorlarni sonlar bilan almashtirish uchun
39. Quyidagilardan qaysi biri chekli oâ€˜lchamli vektor makoniga misol boâ€˜ladi?
# A. R^3
B. Barcha funksiyalar makoni
C. Barcha ketma-ketliklar makoni
D. Cheksiz oâ€˜lchamli matritsalar toâ€˜plami
40. Vektor va vaznli modellar qayerlarda qoâ€˜llaniladi?
# A. Mashinaviy oâ€˜rganish, matnni qayta ishlash va iqtisodiyotda
B. Faqat geometriyada
C. Faqat maktab matematikasida
D. Faqat sonlar nazariyasida	
41. Axborot izlash tizimlarida zona indekslashning asosiy ustunligi nimada?
#A) Hujjatning muhim qismlariga koâ€˜proq vazn berish imkonini yaratadi
B) Hujjat hajmini kamaytiradi
C) Faqat grafik maâ€™lumotlarni saqlaydi
D) Soâ€˜rovlarni qisqartiradi
42. Parametrik indekslar qaysi turdagi maâ€™lumotlar bilan ishlaydi?
#A) Muallif, sana, til kabi strukturali atributlar bilan
B) Faqat matndagi soâ€˜zlar bilan
C) Rasm va video bilan
D) Tasodifiy belgilar bilan
43. TF qiymatiga logarifmik masshtablash qoâ€˜llanishining sababi nima?
#A) Termin koâ€˜p takrorlanganda uning taâ€™sirini haddan tashqari oshib ketmasligini taâ€™minlash
B) Terminlarni oâ€˜chirib tashlash
C) IDF ni nolga tenglashtirish
D) Vektor oâ€˜lchamini kamaytirish
44. IDF koâ€˜rsatkichi qachon katta boâ€˜ladi?
#A) Termin hujjatlar toâ€˜plamida kam uchraganda
B) Termin har bir hujjatda mavjud boâ€˜lsa
C) Termin uzun boâ€˜lsa
D) Termin sarlavhada joylashsa
45. TF-IDF vazni yuqori boâ€˜lgan termin qanday xususiyatga ega?
#A) Hujjat ichida tez-tez, lekin boshqa hujjatlarda kam uchraydi
B) Barcha hujjatlarda bir xil uchraydi
C) Faqat sarlavhada uchraydi
D) Juda qisqa boâ€˜ladi
46. Vektor makon modelida hujjatlar qanday ifodalanadi?
#A) Termin vaznlaridan tashkil topgan vektorlar koâ€˜rinishida
B) Matn satrlari koâ€˜rinishida
C) Jadval ustunlari koâ€˜rinishida
D) Fayl nomlari orqali
47. Soâ€˜rovni vektor sifatida tasvirlash nimani taâ€™minlaydi?
#A) Soâ€˜rov va hujjatlar oâ€˜rtasidagi oâ€˜xshashlikni matematik hisoblashni
B) Soâ€˜rovni avtomatik tarjima qilishni
C) Soâ€˜rov uzunligini kamaytirishni
D) Faqat bitta hujjatni tanlashni
48. Kosinus oâ€˜xshashligi nimani solishtiradi?
#A) Ikki vektor orasidagi burchakni
B) Hujjatlar uzunligini
C) Terminlar sonini
D) Fayl hajmini
49. Hujjat vektori normasi |d| nima uchun ishlatiladi?
#A) Hujjat uzunligining taâ€™sirini kamaytirish uchun
B) Terminlarni oâ€˜chirish uchun
C) Soâ€˜rovni filtrlash uchun
D) Zona indekslarini yaratish uchun
50. Variant TF-IDF funksiyalarining asosiy vazifasi nima?
#A) Turli hujjat uzunliklari va termin chastotalarini adolatli baholash
B) Faqat qisqa hujjatlarni tanlash
C) IDF ni bekor qilish
D) Soâ€˜rovni soddalashtirish
51)Axborot-qidiruv tizimlarida lugâ€˜at (vocabulary) tushunchasi nimani anglatadi?
#A ) Hujjatlarda uchraydigan barcha noyob terminlar majmuasi
B) Hujjatlar ichidagi barcha jumlalar toâ€˜plami
C) Faqat stop-soâ€˜zlardan iborat roâ€˜yxat
D) Qidiruv natijalari reytingi
52)Eâ€™lonlar roâ€˜yxati (postings list) qanday maâ€™lumotni saqlaydi?
#A ) Termin uchragan hujjat IDlari (va qoâ€˜shimcha maâ€™lumotlar).
B) Faqat terminlarning chastotasini
C) Terminlar va ularning sinonimlarini
D) Hujjatlarning toâ€˜liq matnini
53)Lugâ€˜at va eâ€™lonlar roâ€˜yxatini toâ€˜gâ€˜ri tashkil qilishning asosiy maqsadi nima?
#A ) Qidiruv vaqtini qisqartirish va xotira sarfini optimallashtirish.
B) Hujjatlarni shifrlash
C) Matn hajmini koâ€˜paytirish
D) Foydalanuvchi interfeysini soddalashtirish
54)Heaps qonuniga koâ€˜ra lugâ€˜at hajmi (V) qaysi omilga bogâ€˜liq?
#A ) Matndagi umumiy soâ€˜zlar soniga (N).
B) Faqat hujjatlar soniga
C) Soâ€˜zlar ketma-ketligiga
D) Stop-soâ€˜zlar soniga
55)Hujjat chegarasini aniqlash (document delineation) bosqichi nima uchun zarur?
#A ) Matn oqimini alohida hujjatlarga ajratish uchun.
B) Tokenlarni saralash uchun
C) Matnni kodlash uchun
D) Terminlarni ildizga keltirish uchun
56)Belgilar ketma-ketligini dekodlashda (character sequence decoding) notoâ€˜gâ€˜ri kodlash nimaga olib keladi?
#A ) Maxsus belgilar va indeksatsiya jarayoni buziladi.
B) Qidiruv tezlashadi
C) Lugâ€˜at hajmi kamayadi
D) Reyting aniqligi oshadi
57) Tokenizatsiyadan keyingi va normalizatsiyadan oldingi birlik.
#A ) termin.
B) hujjat
C) soâ€™z
D)raqam
58)Stop-soâ€˜zlarni olib tashlashning asosiy afzalligi nimada?
#A ) Indeks hajmini kamaytiradi.
B) Qidiruv natijalari sonini koâ€˜paytiradi
C) Iboralar soâ€˜rovini yaxshilaydi
D) Terminlar sonini oshiradi
59)Skip pointers (oâ€˜tkazib yuborish koâ€˜rsatkichlari) nima uchun ishlatiladi?
#A ) Roâ€˜yxatlar kesishishini tezlashtirish uchun.
B) Lugâ€˜atni kengaytirish uchun
C) Postings roâ€˜yxatlarini siqish uchun
D) Tokenlarni normallashtirish uchun
60) So'zning lug'atdagi ma'noli asosiy shaklini  toppish nima deb ataladi?
#A ) lemmatizatsiya.
B) Tokenizatsiya
C) nomerizatsiya
D) stemming
61. Indekslarni siqishning asosiy maqsadi nima?
  #A) Xotira hajmini kamaytirish.
B) Qidiruvni sekinlashtirish
C) Maâ€™lumotlarni oâ€˜chirish
D) Indeksni murakkablashtirish
62. Qidiruv tizimlarida qaysi indeks turi asosan siqiladi?
  #A) Teskari indeks.
B) Toâ€˜gâ€˜ri indeks
C) Grafik indeks
D) Fayl indeksi
63. Indekslarni siqishda qaysi maâ€™lumotlar saqlanadi?
  #A) Hujjat identifikatorlari va soâ€˜z pozitsiyalari.
B) Foydalanuvchi parollari
C) Rasm fayllari
D) Video maâ€™lumotlar
64. Delta (gap) siqish usuli nimaga asoslanadi?
  #A) Ketma-ket hujjat identifikatorlari orasidagi farqqa.
B) Soâ€˜z uzunligiga
C) Fayl formatiga
D) Rasm oâ€˜lchamiga
65. Variable Byte Encoding usuli nimani siqish uchun ishlatiladi?
  #A) Sonli qiymatlarni.
B) Matnli hujjatlarni
C) Rasm fayllarini
D) Audio fayllarni
66. Gamma va Delta kodlash usullarini kim taklif qilgan?
  #A) Elias.
B) Shannon
C) Turing
D) Knuth
67. Indekslarni siqish qaysi resursdan samarali foydalanishni taâ€™minlaydi?
  #A) Xotira (disk va RAM).
B) Elektr energiyasi
C) Monitor sifati
D) Internet kabeli
68. Indekslarni siqishning mumkin boâ€˜lgan kamchiligi qaysi?
  #A) Ochish (dekompressiya) vaqti talab etilishi
B) Qidiruv natijalari yoâ€˜qolishi
C) Indeks yangilanmasligi
D) Internet uzilishi
69. Indekslarni siqish ayniqsa qaysi holatda muhim?
  #A) Katta hajmdagi maâ€™lumotlar bilan ishlaganda.
B) Kichik matnli fayllarda
C) Oâ€˜yin dasturlarida
D) Grafik dizaynda
70. Zamonaviy qidiruv tizimlarida indekslarni siqish nimani taâ€™minlaydi?
  #A) Tez va samarali qidiruvni.
B) Chiroyli interfeysni
C) Fayllarni chop etishni
D) Internetni oâ€˜chirishni
71. AQT baholashning asosiy maqsadi nimani miqdoriy oâ€˜lchashdan iborat? 
#A) Tegishlilik (Relevance) tushunchasini.
B) Tizimning ishlash tezligini (Latency) 
C) Indeksning umumiy hajmini 
D) Qidiruv soâ€˜rovlarining oâ€˜rtacha uzunligini
72. Qidiruv natijalarining Aniqligi (Precision) qanday oâ€˜lchanadi? 
#A) Topilgan dolzarb hujjatlar soni / Topilgan barcha hujjatlar soni.
B) Topilgan barcha hujjatlar soni / Barcha dolzarb hujjatlar soni 
C) Dolzarb boâ€˜lmagan hujjatlar soni / Topilgan barcha hujjatlar soni 
D) Barcha dolzarb hujjatlar soni / Topilgan dolzarb hujjatlar soni
73. Qidiruv natijalarining Toâ€˜liqligi (Recall) qanday oâ€˜lchanadi? 
#A) Topilgan dolzarb hujjatlar soni / Barcha dolzarb hujjatlar soni.
B) Topilgan dolzarb hujjatlar soni / Topilgan barcha hujjatlar soni 
C) Barcha dolzarb boâ€˜lmagan hujjatlar soni / Topilgan barcha hujjatlar soni 
D) Topilgan nodolzarb hujjatlar soni / Topilgan dolzarb hujjatlar soni
74. Axborot-qidiruv tizimining aniqlik (P) va toâ€˜liqlik (R) koâ€˜rsatkichlarini birlashtiruvchi, ularning uygâ€˜unlashgan oâ€˜rtacha qiymatini hisoblaydigan metrika nima deb ataladi? 
#A) F-oâ€˜lchov (F-measure).
B) R-oâ€˜lchov (R-measure) 
C) P-oâ€˜lchov (P-measure) 
D) MAP (Mean Average Precision)
75. AQTni baholash uchun foydalaniladigan hujjatlar korpusi, soâ€˜rovlar toâ€˜plami va har bir soâ€˜rov uchun hujjatlarning dolzarblik baholarini oâ€˜z ichiga olgan maxsus toâ€˜plamning nomi nima? 
#A) Test toâ€˜plami (Test Collection).
B) Katta maâ€™lumotlar bazasi (Big Data) 
C) Boshlangâ€˜ich korpus 
D) Sinov maâ€™lumotlar fayli (Log File)
76. AQT baholash sohasidagi eng mashhur, yiliga bir marta oâ€˜tkaziladigan va standart Test toâ€˜plamlarini yaratishga yordam beruvchi xalqaro konferensiya qaysi? 
#A) TREC (Text REtrieval Conference).
B) CLEF (Cross-Language Evaluation Forum) 
C) NTCIR (NII Test Collection for IR) 
D) ACL (Association for Computational Linguistics)
77. Natijalarning tartiblanishini (ranking) hisobga oladigan va har bir soâ€˜rov uchun oâ€˜rtacha aniqlikni oâ€˜lchaydigan metrika nima deb ataladi? 
#A) Oâ€˜rtacha Aniqlik (Average Precision).
B) F-oâ€˜lchov C) Diskontlangan Kumulyativ Foyda (DCG) 
D) Toâ€˜liqlik (Recall)
78. Bir nechta soâ€˜rovlar boâ€˜yicha Oâ€˜rtacha Aniqlik (Average Precision) qiymatlarining oâ€˜rtachasi qanday ataladi? 
#A) MAP (Mean Average Precision).
B) MAC (Mean Average Coverage) 
C) DCG (Discounted Cumulative Gain) 
D) BPP (Binary Preference Points)
79. Qidiruv natijalarining tartibini hisobga olib, yuqori oâ€˜rinlarda kelgan dolzarb hujjatlarga past oâ€˜rinlardagiga qaraganda koâ€˜proq qiymat beruvchi metrika qaysi? 
#A) DCG (Discounted Cumulative Gain).
B) Aniqlik (Precision) 
C) Toâ€˜liqlik (Recall) 
D) F-oâ€˜lchov
80. AQTni baholashda qidiruv tezligi va bir vaqt birligida bajarilgan soâ€˜rovlar soni kabi koâ€˜rsatkichlar qaysi toifadagi mezonlarga kiradi? 
#A) Samaradorlik (Efficiency) mezonlari.
B) Dolzarblik (Effectiveness) mezonlari 
C) Xarajat (Cost) mezonlari 
D) Foydalanuvchi interfeysi mezonlari
81. Oâ€˜zbek tilida statistik tahlilni murakkablashtiruvchi asosiy omil qaysi?
A) Soâ€˜zlarning faqat lotin alifbosida yozilishi
#B) Soâ€˜zlarning morfologik oâ€˜zgarishii va qoâ€˜shimchalar orqali yasalishi.
C) Soâ€˜zlar orasida sinonimlarning kamligi
D) Matnlarning kichik hajmda boâ€˜lishi
82. Statistik siqishda yuqori chastotali soâ€˜zlarga qanday yondashuv qoâ€˜llaniladi?
A) Ular lugâ€˜atdan olib tashlanadi
B) Ular uchun uzun kodlar ajratiladi
#C) Ular uchun qisqa kodlar ajratiladii.
D) Ular faqat qoâ€˜lda kodlanadi
83. Zipf va Heaps qonunlari asosan nimani tahlil qilishda qoâ€˜llaniladi?
A) Matnning grammatik tuzilishini
B) Soâ€˜zlar maâ€™nosini
#C) Soâ€˜zlarning chastota va taqsimlanishini.
D) Matn tarjimasini
84. Heaps qonuni nimani bashorat qilish uchun ishlatiladi?
A) Soâ€˜zlarning semantik bogâ€˜lanishini
#B) Lugâ€˜at hajmini matn uzunligiga bogâ€˜lab baholashnii.
C) Matndagi gaplar sonini aniqlashni
D) Soâ€˜zlarning grammatik shakllarini
85. Heaps qonunidagi ð›½ koeffitsienti nimani ifodalaydi?
A) Matn tilini
B) Soâ€˜zlar oâ€˜rtasidagi sinonimiyani
#C) Lugâ€˜at hajmining matn uzunligiga nisbatan oâ€˜sish tezligini.
D) Eng koâ€˜p ishlatiladigan soâ€˜zlar sonini
86. Nima sababdan oâ€˜zbek tilida ð›½ qiymati 0.5 dan biroz yuqori boâ€˜lishi mumkin?
A) Soâ€˜zlar kam ishlatilgani sababli
B) Oâ€˜zbek tilida prefikslar koâ€˜p boâ€˜lgani uchun
#C) Qoâ€˜shimchalar va morfologik oâ€˜zgarishlar tez-tez yuz berishi sababli.
D) Matnlar hajmi kichik boâ€˜lgani uchun
87. Heaps qonuni siqish algoritmlarida qanday qaror qabul qilishga yordam beradi?
A) Qaysi soâ€˜zlarni tarjima qilishni
#B) Qaysi soâ€˜zlar uchun qisqa kod ajratish samarasiz ekaninii.
C) Qaysi gaplarni olib tashlashni
D) Qaysi belgilarni almashtirishni
88. Zipf qonuni nimani ifodalaydi?
A) Soâ€˜zlarning grammatik tuzilishini
#B) Atamalar chastotasining ularning tartib raqamiga bogâ€˜liqliginii.
C) Matn uzunligining lugâ€˜at hajmiga taâ€™sirini
D) Soâ€˜zlarning semantik yaqinligini
89. Lugâ€˜atni siqishning asosiy maqsadi nima?
A) Matnni tarjima qilish
#B) Lugâ€˜atdagi atamalarni ixcham shaklda saqlab, xotira hajmini kamaytirish.
C) Soâ€˜zlar sonini koâ€˜paytirish
D) Grammatik tahlilni murakkablashtirish
90. Gamma kodlari asosan qaysi turdagi qiymatlar uchun samarali hisoblanadi?
A) Juda katta butun sonlar uchun
B) Matnli maâ€™lumotlar uchun
#C) Kichik butun sonlar va kichik delta qiymatlar uchun.
D) Haqiqiy (real) sonlar uchun
91. Relevance feedback (mos keluvchilik qaytarilishi) nima uchun ishlatiladi? 
#a) Qidiruv natijalarini yaxshilash uchun foydalanuvchi fikriga asoslanib soâ€˜rovni qayta shakllantirish.
b) Fayllarni oâ€˜chirish uchun
c) Internetni tezlashtirish uchun
d) Kompyuter viruslarini tozalash uchun
92. Rocchio algoritmi qanday vazifani bajaradi?
#a) Foydalanuvchi tanlagan mos va mos kelmaydigan hujjatlar asosida soâ€˜rovni qayta hisoblash.
b) Parollarni yaratish
c) Rasmlarni kichraytirish
d) Muzikani tahrirlash
93. Pseudo relevance feedback (soxta mos keluvchilik qaytarilishi) nima?
#a) Foydalanuvchidan soâ€˜ramasdan, eng yuqori natijalarga asoslanib soâ€˜rovni kengaytirish.
b) Foydalanuvchidan har doim soâ€˜rash
c) Hech qanday natija bermaslik
d) Faqat birinchi natijani koâ€˜rsatish
94. Relevance feedback qachon yaxshi ishlaydi?
#a) Foydalanuvchi aniq fikr bildirgan va boshlangâ€˜ich natijalar yaxshi boâ€˜lganda.
b) Internet uzilib qolganda
c) Kompyuter oâ€˜chirilganda
d) Hech qachon ishlamaydi
95. Veb (internet)da relevance feedback qanday qoâ€˜llaniladi?
#a) Foydalanuvchi bosgan havolalar va vaqt sarflagan sahifalar asosida.
b) Faqat reklama orqali
c) Tasodifiy usulda
d) Hech qachon qoâ€™llanilmaydi
96. Relevance feedback strategiyalarini baholash (evaluation) nimaga qarab amalga oshiriladi?
#a) Qidiruv natijalarining sifati qanchalik yaxshilanganiga qarab.
b) Kompyuter narxiga qarab
c) Internet tezligiga qarab
d) Foydalanuvchi yoshiga qarab
97. Indirect relevance feedback (bilvosita mos keluvchilik qaytarilishi) nima? 
#a) Foydalanuvchi harakatlari (kliklar, vaqt) orqali bilvosita fikr olish.
b) Foydalanuvchiga toâ€˜gâ€˜ridan-toâ€˜gâ€˜ri telefon qilish
c) Email yuborish
d) SMS joâ€™natish
98. Global metodlar (global methods) soâ€˜rovni qayta shakllantirish uchun nimadan foydalanadi?
#a) Butun hujjatlar toâ€˜plamidan olingan umumiy statistik maâ€™lumotlar.
b) Faqat bitta hujjatdan
c) Faqat foydalanuvchi ismidan
d) Tasodifiy raqamlardan
99. Lugâ€˜at vositalari (vocabulary tools) soâ€˜rovni qayta shakllantirish uchun nima beradi?
#a) Sinonimlar, bogâ€˜liq atamalar va muqobil soâ€˜zlar.
b) Faqat tarjima
c) Faqat imlo xatolari
d) Hech narsa
100. Query expansion (soâ€˜rovni kengaytirish) ning maqsadi nima?
#a) Soâ€˜rovga qoâ€˜shimcha tegishli atamalar qoâ€˜shib, koâ€˜proq mos natijalar toppish.
b) Soâ€˜rovni qisqartirish
c) Soâ€˜rovni oâ€˜chirish
d) Soâ€˜rovni nusxalash
100.	Ehtimoliy yondashuvning asosiy afzalligi nimada?
a) Eng tez ishlaydi
#b) Matematik jihatdan aniq va interpretatsiya qilish oson (masalan: 0.91 = 91% ehtimol).
c) Eng kam xotira talab qiladi
d) Faqat ingliz tili uchun
101.	Bayes teoremasi formulasida P(A|B) nimani bildiradi?
a) A va B ning umumiy ehtimoli
#b) B yuz berganda A ning shartli ehtimoli.
c) A ning mustaqil ehtimoli
d) B ning chastotasi
102.	Binary Independence Model (BIM) ning asosiy soddalashtirishlari qaysilar?
a) Faqat ingliz so'zlarini ishlatish
#b) Binary (bor/yo'q), Independence (mustaqillik), Class assumptions (sinf taxminlari).
c) Faqat qisqa hujjatlar uchun
d) TF ni hisobga olish
103.	BM25 ning BIM dan asosiy farqi nimada?
a) Faqat tezroq ishlaydi
#b) TF ni hisobga oladi, hujjat uzunligini normalizatsiya qiladi va IDF qo'shadi.
c) Faqat binary xususiyatlar bilan ishlaydi
d) Smoothing ishlatmaydi
104.	BM25 formulasida kâ‚ parametri nimani boshqaradi?
a) Hujjat uzunligi
#b) TF saturation (to'yinish) tezligini â€“ kichik kâ‚ = tez to'yinish, katta kâ‚ = sekin to'yinish.
c) IDF qiymatini
d) Korpus hajmini
105.	BM25 formulasida b parametri nimani boshqaradi?
a) TF saturation ni
#b) Uzunlik normalizatsiyasining kuchini â€“ b = 0 (jazo yo'q), b = 1 (to'liq jazo).
c) IDF ni
d) So'rov uzunligini
106.	BM25 formulasida IDF ning maqsadi nima?
a) Hujjat uzunligini hisoblash
#b) Noyob terminlarga (kam hujjatlarda uchraydigan) yuqori vazn berish.
c) TF ni normalizatsiya qilish
d) So'zlarni tarjima qilish
107.	BM25F modelining BM25 dan asosiy farqi nimada?
a) Tezroq ishlaydi
#b) Field-aware: har bir maydon (title, abstract, body) uchun alohida vazn va normalizatsiya.
c) Faqat qisqa hujjatlar uchun
d) IDF ishlatmaydi
108.	Pseudo Relevance Feedback (PRF) qanday ishlaydi?
a) Foydalanuvchidan feedback so'raydi
#b) Top K ta natijani avtomatik "tegishli" deb hisoblaydi va so'rovni kengaytiradi.
c) Faqat BM25 ni ishlatadi
d) Hech qanday feedback ishlatmaydi
109.	Elasticsearch da default qanday ranking algoritmi ishlatiladi?
a) TF-IDF
#b) BM25.
c) PageRank
d) Naive Bayes
110.	Til modeli (Language Model) nima?
a) Matnlarni tarjima qilish dasturi
#b) So'zlar ketma-ketligining ehtimolligini hisoblovchi matematik model.
c) Grammatik xatolarni topuvchi dastur
d) Faqat ingliz tili uchun mo'ljallangan model
111.	N-gram modellarida Unigram (1-gram) qanday ishlaydi?
a) Har bir so'z oldingi ikkita so'zga bog'liq
#b) Har bir so'z mustaqil, kontekstsiz hisoblanadi.
c) Faqat juft so'zlarni tahlil qiladi
d) So'zlarning grammatik shaklini o'zgartiradi
112.	Query Likelihood Model ning asosiy g'oyasi nimada?
a) So'rovni tarjima qilish
#b) Hujjatdan so'rovni generatsiya qilish ehtimolini hisoblash: P(so'rov | hujjat).
c) Faqat BM25 ni yaxshilash
d) So'zlarning chastotasini sanash
113.	Smoothing (silliqlash) usuli qanday muammoni hal qiladi?
a) Matnni tezroq qayta ishlash
#b) Zero probability (nol ehtimollik) muammosini oldini olish.
c) Hujjatlarni tarjima qilish
d) Grammatik xatolarni tuzatish
114.	Jelinekâ€“Mercer smoothing formulasida Î» (lambda) parametri nimani bildiradi?
a) Hujjat uzunligi
#b) Korpus va hujjat ehtimolliklarini aralashtirish nisbati (odatda 0.1â€“0.3).
c) So'z chastotasi
d) TF-IDF vazni
115.	Dirichlet smoothing ning Jelinekâ€“Mercer dan asosiy farqi nimada?
a) Tezroq ishlaydi
#b) Hujjat uzunligiga qarab turli darajada smoothing qo'llaydi (qisqa hujjatlarga ko'proq).
c) Faqat o'zbek tili uchun
d) Smoothing umuman qo'llamaydi
116.	Ponte va Croft (1998) ning asosiy hissasi nima edi?
a) BM25 ni kashf qildilar
#b) Query Likelihood modelini qidiruvga qo'lladilar va smoothing muhimligini ko'rsatdilar.
c) Birinchi qidiruv tizimini yaratdilar
d) TF-IDF ni kashf qildilar
117.	Bigram (2-gram) modeli qanday afzallikka ega?
a) Eng tez ishlaydi
#b) So'zlar ketma-ketligini va juftliklarni hisobga oladi (masalan: â€œNew Yorkâ€).
c) Xotira kam talab qiladi
d) Faqat qisqa matnlar uchun
118.	O'zbek tili uchun til modellarida qanday maxsus qiyinchilik mavjud?
a) Lotin alifbosi
#b) Morfologik boylik: bitta ildizning ko'p shakllari (kitob, kitoblar, kitobni...).
c) So'zlar juda qisqa
d) Kod-switching umuman yo'q
119.	BERT modelining klassik til modellaridan asosiy farqi nimada?
a) Tezroq ishlaydi
#b) Ikki tomonlama kontekstni tushunadi (oldingi va keyingi so'zlardan).
c) Faqat unigram ishlatadi
d) Smoothing talab qilmaydi
120.	 Naive Bayes algoritmi nima uchun â€œNaiveâ€ (soddalashtirilgan) deb ataladi?
a) Model oâ€˜qitish jarayoni sodda
#b) Barcha xususiyatlar (soâ€˜zlar) bir-biridan mustaqil deb taxmin qilinadi.
c) Faqat sodda matnlar uchun ishlatiladi
d) Hisoblash murakkabligi past
121.	Bernoulli modeli va Multinomial modeli oâ€˜rtasidagi asosiy farq nimada?
a) Bernoulli tezroq ishlaydi
b) Multinomial faqat oâ€˜zbek tili uchun
c) Bernoulli koâ€˜p sinfli tasnif uchun ishlatiladi
#d) Bernoulli soâ€˜z mavjudligini (bor/yoâ€˜q), Multinomial esa chastotasini hisobga oladi.
122.	Laplace Smoothing (silliqlash) usuli qanday muammoni hal qiladi?
a) Modelni tezlashtirish
b) Matnni tozalash
c) Stop-soâ€˜zlarni olib tashlash
#d) Zero probability (nol ehtimollik) muammosini oldini olish.
123.	Chi-square (X-kvadrat) xususiyat tanlash usulining vazifasi nima?
a) Matnlarni tarjima qilish
b) Hujjatlarni saralash.
#c) Soâ€˜z va sinf orasidagi statistik bogâ€˜liqlikni baholash va eng muhim xususiyatlarni tanlash
d) Grammatik xatolarni topish
124.	Matn tasnifida F1-score metrikasi nima uchun muhim?
a) Faqat toâ€˜gâ€˜ri tasniflangan hujjatlarni koâ€˜rsatadi
b) Eng tez hisoblash mumkin
#c) Precision va Recall ning garmonik oâ€˜rtachasini hisoblab, muvozanatli baho beradi.
d) Faqat ikkilik tasnifda ishlatiladi
125.	Mutual Information (MI) usuli xususiyat tanlashda nimani baholaydi?
a) Soâ€˜zning uzunligini
b) Hujjat hajmini
c) Grammatik toâ€˜gâ€˜rilikni
#d) Soâ€˜z va sinf orasidagi bogâ€˜liqlikni.
126.	Oâ€˜zbek tili uchun matn tasnifida qanday qiyinchilik mavjud?
a) Yozuv tizimi murakkab
b) Soâ€˜zlar juda qisqa
c) Faqat lotin alifbosida yoziladi
#d) Agglutinativ til boâ€˜lib, bitta soâ€˜zda koâ€˜p qoâ€˜shimchalar boâ€˜ladi (masalan: â€œkitoblarimdanâ€).
127.	Multinomial Naive Bayes modelida soâ€˜zlar qanday hisobga olinadi?
a) Faqat soâ€˜z mavjudligini tekshiradi (bor/yoâ€˜q)
b) Faqat eng koâ€˜p uchraydigan soâ€˜zlarni tanlaydi
#c) Soâ€˜zning necha marta uchraganini (chastotasini) hisobga oladi.
d) Hujjat uzunligini hisobga olmaydi
128.	Xususiyatlarni tanlash (Feature Selection) ning asosiy maqsadi nima?
a) Barcha soâ€˜zlarni saqlash
b) Matnni tarjima qilish
c) Faqat ingliz soâ€˜zlarini tanlash
#d) Shovqinli va kam foydali soâ€˜zlarni olib tashlab, eng muhimlarini saqlash.
129.	Spam filtrlashda qaysi Naive Bayes modeli koâ€˜proq ishlatiladi va nima uchun?
a) Multinomial, chunki chastota muhim
b) Ikkalasi bir xil
c) Hech qaysi biri ishlatilmaydi
#d) Bernoulli, chunki soâ€˜z mavjudligi spam aniqlashda yetarli.
130.	Vektor Fazo Modelida (VSM) har bir oâ€˜lchov (oâ€˜q) nimani bildiradi?
a) Hujjatlarning uzunligini
#b) Korpusdagi noyob terminlardan birini.
c) Hujjatning yaratilgan sanasini
d) Foydalanuvchi soâ€˜rovini
131.	TF-IDF formulasida IDF (Inverse Document Frequency) ning asosiy vazifasi nima?
a) Soâ€˜zning hujjatdagi chastotasini hisoblash
#b) Soâ€˜zning korpusdagi noyobligini (kam uchraydigan soâ€˜zlarni yuqori baholash) aniqlash.
c) Hujjatning umumiy uzunligini normalizatsiya qilish
d) Soâ€˜zlarning grammatik shaklini aniqlash
132.	Kosinus oâ€˜xshashligi metrikasining asosiy afzalligi nima?
a) Eng tez hisoblash mumkin
#b) Hujjat uzunligiga bogâ€˜liq emas, faqat yoâ€˜nalishni oâ€˜lchaydi.
c) Eng aniq natija beradi
d) Barcha tillarda bir xil ishlaydi
133.	Sparsity (gâ€˜ovaklik) muammosi nima haqida?
a) Hujjatlar juda qisqa boâ€˜lishi
#b) Vektor fazoda elementlarning katta qismi (99%+) nolga teng boâ€˜lishi.
c) Maâ€˜lumotlar bazasi toâ€˜lmasligi
d) Korpusda soâ€˜zlar kam boâ€˜lishi
134.	Word2Vec ning Skip-gram modeli qanday ishlaydi?
a) Kontekst soâ€˜zlardan markaziy soâ€˜zni bashorat qiladi
#b) Markaziy soâ€˜zdan kontekst soâ€˜zlarni bashorat qiladi.
c) Soâ€˜zlarni alifbo tartibida saralaydi
d) Soâ€˜zlarning grammatik shaklini oâ€˜zgartiradi
135.	Yevklid masofasining matn tahlilida asosiy kamchiligi nima?
a) Hisoblash juda sekin
b) Faqat ingliz tili uchun ishlaydi.
#c) Hujjat uzunligiga bogâ€˜liq (length bias muammosi)
d) Manfiy qiymatlar bera olmaydi
136.	Rocchio algoritmida har bir sinf qanday ifodalanadi?
a) Eng uzun hujjat orqali
#b) Bitta markaziy vektor (centroid) orqali.
c) Eng qisqa hujjat orqali
d) Tasodifiy tanlangan hujjat orqali
137.	fastText ning Word2Vec dan asosiy farqi nimada?
a) Tezroq ishlaydi
#b) Soâ€˜zni ichki n-grammalarga ajratadi va OOV muammosini hal qiladi.
c) Faqat ingliz tili uchun moâ€˜ljallangan
d) Kamroq xotira talab qiladi
138.	Bias-Variance Tradeoff da â€œHigh Biasâ€ (yuqori tarafkashlik) qanday holatni bildiradi?
a) Model juda murakkab va overfitting
#b) Model juda sodda va underfitting.
c) Model optimal ishlayapti
d) Maâ€˜lumotlarda xato bor
139.	BERT modelining asosiy innovatsiyasi nimada?
a) Eng kichik model hajmi
#b) Har bir soâ€˜z uchun kontekstga qarab turli vektorlar beradi.
c) Faqat oâ€˜zbek tili uchun ishlab chiqilgan
d) Internetga ulanish talab qilmaydi
140.	Naive Bayes algoritmida â€œNaiveâ€ (sodda) taxmin nima haqida?
a) Model oâ€˜qitish jarayoni sodda
#b) Barcha soâ€˜zlar bir-biridan mustaqil deb hisoblanadi..
c) Faqat sodda matnlar uchun ishlatiladi
d) Hisoblash murakkabligi past
141.	SVM (Support Vector Machine) algoritmining asosiy maqsadi nima?
a) Eng koâ€˜p xususiyatlarni topish
b) Eng tez tasniflovchi qurish
#c) Ikki sinf orasida maksimal margin bilan gipertekislik toppish.
d) Barcha maâ€™lumotlarni toâ€˜gâ€˜ri tasniflash
142.	Laplace Smoothing nima uchun ishlatiladi?
a) Modelni tezlashtirish uchun
#b) Nol ehtimollikni oldini olish uchun.
c) Xotira sarfini kamaytirish uchun
d) Aniqlikni oshirish uchun
143.	Soft-Margin SVM da C parametri nimani bildiradi?
a) Model aniqligini
b) Oâ€˜qitish tezligini
#c) Regularizatsiya parametri (jarima koeffitsienti).
d) Support Vectors sonini
144.	Learning to Rank (LTR) ning qaysi yondashuvi butun roâ€˜yxatni birdan optimizatsiya qiladi?
a) Pointwise Approach
b) Pairwise Approach
#c) Listwise Approach.
d) Hybrid Approach
145.	Random Forest algoritmi qanday ishlaydi?
a) Bitta chuqur qaror daraxti yaratadi
#b) Koâ€˜plab mustaqil daraxtlarning ensemble (toâ€˜plami)dan foydalanadi.
c) Faqat eng muhim xususiyatlarni tanlaydi
d) Ketma-ket daraxtlar zanjirini quradi
146.	NDCG (Normalized Discounted Cumulative Gain) metrikasi nima uchun ishlatiladi?
a) Tasnif aniqligini oâ€˜lchash
#b) Ranking natijalarining sifatini baholash.
c) Model tezligini oâ€˜lchash
d) Xotira sarfini aniqlash
147.	RBF (Radial Basis Function) kernel qachon eng yaxshi natija beradi?
a) Katta korpuslar uchun (>100K hujjat)
b) Chiziqli ajratiladigan maâ€™lumotlar uchun
#c) Kichik korpuslar va nochiziqli patternlar uchun.
d) Real-time production sistemalar uchun
148.	ColBERT modelining asosiy afzalligi nimada?
a) Eng arzon model
#b) Cross-Encoder aniqligiga yaqin, lekin Bi-Encoder tezligida.
c) Eng kichik model hajmi
d) Eng tez oâ€˜qitish jarayoni
149.	Decision Tree da Information Gain (IG) nima uchun hisoblanadi?
a) Model aniqligini aniqlash uchun
#b) Eng yaxshi ajratish xususiyatini tanlash uchun.
c) Overfittingni oldini olish uchun
d) Daraxt chuqurligini aniqlash uchun
150.	Klasterlash (Clustering) nima?
a) Hujjatlarni oldindan belgilangan sinflarga ajratish
b) Faqat matnlarni tarjima qilish
#c) Oâ€˜xshash hujjatlarni guruhlarga (klasterlarga) avtomatik ajratish.
d) Hujjatlarni oâ€˜chirish jarayoni
151.	Ehtimoliy yondashuvning asosiy afzalligi nimada?
a) Eng tez ishlaydi
#b) Matematik jihatdan aniq va interpretatsiya qilish oson (masalan: 0.91 = 91% ehtimol).
c) Eng kam xotira talab qiladi
d) Faqat ingliz tili uchun
152.	Bayes teoremasi formulasida P(A|B) nimani bildiradi?
a) A va B ning umumiy ehtimoli
#b) B yuz berganda A ning shartli ehtimoli.
c) A ning mustaqil ehtimoli
d) B ning chastotasi
153.	Binary Independence Model (BIM) ning asosiy soddalashtirishlari qaysilar?
a) Faqat ingliz so'zlarini ishlatish
#b) Binary (bor/yo'q), Independence (mustaqillik), Class assumptions (sinf taxminlari).
c) Faqat qisqa hujjatlar uchun
d) TF ni hisobga olish
154.	BM25 ning BIM dan asosiy farqi nimada?
a) Faqat tezroq ishlaydi
#b) TF ni hisobga oladi, hujjat uzunligini normalizatsiya qiladi va IDF qo'shadi.
c) Faqat binary xususiyatlar bilan ishlaydi
d) Smoothing ishlatmaydi
155.	BM25 formulasida kâ‚ parametri nimani boshqaradi?
a) Hujjat uzunligi
#b) TF saturation (to'yinish) tezligini â€“ kichik kâ‚ = tez to'yinish, katta kâ‚ = sekin to'yinish.
c) IDF qiymatini
d) Korpus hajmini
156.	BM25 formulasida b parametri nimani boshqaradi?
a) TF saturation ni
#b) Uzunlik normalizatsiyasining kuchini â€“ b = 0 (jazo yo'q), b = 1 (to'liq jazo).
c) IDF ni
d) So'rov uzunligini
157.	BM25 formulasida IDF ning maqsadi nima?
a) Hujjat uzunligini hisoblash
#b) Noyob terminlarga (kam hujjatlarda uchraydigan) yuqori vazn berish.
c) TF ni normalizatsiya qilish
d) So'zlarni tarjima qilish
158.	BM25F modelining BM25 dan asosiy farqi nimada?
a) Tezroq ishlaydi
#b) Field-aware: har bir maydon (title, abstract, body) uchun alohida vazn va normalizatsiya.
c) Faqat qisqa hujjatlar uchun
d) IDF ishlatmaydi
159.	Pseudo Relevance Feedback (PRF) qanday ishlaydi?
a) Foydalanuvchidan feedback so'raydi
#b) Top K ta natijani avtomatik "tegishli" deb hisoblaydi va so'rovni kengaytiradi.
c) Faqat BM25 ni ishlatadi
d) Hech qanday feedback ishlatmaydi
160.	Elasticsearch da default qanday ranking algoritmi ishlatiladi?
a) TF-IDF
#b) BM25.
c) PageRank
d) Naive Bayes
161.	Til modeli (Language Model) nima?
a) Matnlarni tarjima qilish dasturi
#b) So'zlar ketma-ketligining ehtimolligini hisoblovchi matematik model.
c) Grammatik xatolarni topuvchi dastur
d) Faqat ingliz tili uchun mo'ljallangan model
162.	N-gram modellarida Unigram (1-gram) qanday ishlaydi?
a) Har bir so'z oldingi ikkita so'zga bog'liq
#b) Har bir so'z mustaqil, kontekstsiz hisoblanadi.
c) Faqat juft so'zlarni tahlil qiladi
d) So'zlarning grammatik shaklini o'zgartiradi
163.	Query Likelihood Model ning asosiy g'oyasi nimada?
a) So'rovni tarjima qilish
#b) Hujjatdan so'rovni generatsiya qilish ehtimolini hisoblash: P(so'rov | hujjat).
c) Faqat BM25 ni yaxshilash
d) So'zlarning chastotasini sanash
164.	Smoothing (silliqlash) usuli qanday muammoni hal qiladi?
a) Matnni tezroq qayta ishlash
#b) Zero probability (nol ehtimollik) muammosini oldini olish.
c) Hujjatlarni tarjima qilish
d) Grammatik xatolarni tuzatish
165.	Jelinekâ€“Mercer smoothing formulasida Î» (lambda) parametri nimani bildiradi?
a) Hujjat uzunligi
#b) Korpus va hujjat ehtimolliklarini aralashtirish nisbati (odatda 0.1â€“0.3).
c) So'z chastotasi
d) TF-IDF vazni
166.	Dirichlet smoothing ning Jelinekâ€“Mercer dan asosiy farqi nimada?
a) Tezroq ishlaydi
#b) Hujjat uzunligiga qarab turli darajada smoothing qo'llaydi (qisqa hujjatlarga ko'proq).
c) Faqat o'zbek tili uchun
d) Smoothing umuman qo'llamaydi
167.	Ponte va Croft (1998) ning asosiy hissasi nima edi?
a) BM25 ni kashf qildilar
#b) Query Likelihood modelini qidiruvga qo'lladilar va smoothing muhimligini ko'rsatdilar.
c) Birinchi qidiruv tizimini yaratdilar
d) TF-IDF ni kashf qildilar
168.	Bigram (2-gram) modeli qanday afzallikka ega?
a) Eng tez ishlaydi
#b) So'zlar ketma-ketligini va juftliklarni hisobga oladi (masalan: â€œNew Yorkâ€).
c) Xotira kam talab qiladi
d) Faqat qisqa matnlar uchun
169.	O'zbek tili uchun til modellarida qanday maxsus qiyinchilik mavjud?
a) Lotin alifbosi
#b) Morfologik boylik: bitta ildizning ko'p shakllari (kitob, kitoblar, kitobni...).
c) So'zlar juda qisqa
d) Kod-switching umuman yo'q
170.	BERT modelining klassik til modellaridan asosiy farqi nimada?
a) Tezroq ishlaydi
#b) Ikki tomonlama kontekstni tushunadi (oldingi va keyingi so'zlardan).
c) Faqat unigram ishlatadi
d) Smoothing talab qilmaydi
171.	 Naive Bayes algoritmi nima uchun â€œNaiveâ€ (soddalashtirilgan) deb ataladi?
a) Model oâ€˜qitish jarayoni sodda
#b) Barcha xususiyatlar (soâ€˜zlar) bir-biridan mustaqil deb taxmin qilinadi.
c) Faqat sodda matnlar uchun ishlatiladi
d) Hisoblash murakkabligi past
172.	Bernoulli modeli va Multinomial modeli oâ€˜rtasidagi asosiy farq nimada?
a) Bernoulli tezroq ishlaydi
b) Multinomial faqat oâ€˜zbek tili uchun
c) Bernoulli koâ€˜p sinfli tasnif uchun ishlatiladi
#d) Bernoulli soâ€˜z mavjudligini (bor/yoâ€˜q), Multinomial esa chastotasini hisobga oladi.
173.	Laplace Smoothing (silliqlash) usuli qanday muammoni hal qiladi?
a) Modelni tezlashtirish
b) Matnni tozalash
c) Stop-soâ€˜zlarni olib tashlash
#d) Zero probability (nol ehtimollik) muammosini oldini olish.
174.	Chi-square (X-kvadrat) xususiyat tanlash usulining vazifasi nima?
a) Matnlarni tarjima qilish
b) Hujjatlarni saralash
#c) Soâ€˜z va sinf orasidagi statistik bogâ€˜liqlikni baholash va eng muhim xususiyatlarni tanlash.
d) Grammatik xatolarni topish
175.	Matn tasnifida F1-score metrikasi nima uchun muhim?
a) Faqat toâ€˜gâ€˜ri tasniflangan hujjatlarni koâ€˜rsatadi
b) Eng tez hisoblash mumkin
#c) Precision va Recall ning garmonik oâ€˜rtachasini hisoblab, muvozanatli baho beradi.
d) Faqat ikkilik tasnifda ishlatiladi
176.	Mutual Information (MI) usuli xususiyat tanlashda nimani baholaydi?
a) Soâ€˜zning uzunligini
b) Hujjat hajmini
c) Grammatik toâ€˜gâ€˜rilikni
#d) Soâ€˜z va sinf orasidagi bogâ€˜liqlikni.
177.	Oâ€˜zbek tili uchun matn tasnifida qanday qiyinchilik mavjud?
a) Yozuv tizimi murakkab
b) Soâ€˜zlar juda qisqa
c) Faqat lotin alifbosida yoziladi
#d) Agglutinativ til boâ€˜lib, bitta soâ€˜zda koâ€˜p qoâ€˜shimchalar boâ€˜ladi (masalan: â€œkitoblarimdanâ€).
178.	Multinomial Naive Bayes modelida soâ€˜zlar qanday hisobga olinadi?
a) Faqat soâ€˜z mavjudligini tekshiradi (bor/yoâ€˜q)
b) Faqat eng koâ€˜p uchraydigan soâ€˜zlarni tanlaydi
#c) Soâ€˜zning necha marta uchraganini (chastotasini) hisobga oladi.
d) Hujjat uzunligini hisobga olmaydi
179.	Xususiyatlarni tanlash (Feature Selection) ning asosiy maqsadi nima?
a) Barcha soâ€˜zlarni saqlash
b) Matnni tarjima qilish
c) Faqat ingliz soâ€˜zlarini tanlash
#d) Shovqinli va kam foydali soâ€˜zlarni olib tashlab, eng muhimlarini saqlash.
180.	Spam filtrlashda qaysi Naive Bayes modeli koâ€˜proq ishlatiladi va nima uchun?
a) Multinomial, chunki chastota muhim
b) Ikkalasi bir xil
c) Hech qaysi biri ishlatilmaydi
#d) Bernoulli, chunki soâ€˜z mavjudligi spam aniqlashda yetarli.
181.	Vektor Fazo Modelida (VSM) har bir oâ€˜lchov (oâ€˜q) nimani bildiradi?
a) Hujjatlarning uzunligini
#b) Korpusdagi noyob terminlardan birini.
c) Hujjatning yaratilgan sanasini
d) Foydalanuvchi soâ€˜rovini
182.	TF-IDF formulasida IDF (Inverse Document Frequency) ning asosiy vazifasi nima?
a) Soâ€˜zning hujjatdagi chastotasini hisoblash
#b) Soâ€˜zning korpusdagi noyobligini (kam uchraydigan soâ€˜zlarni yuqori baholash) aniqlash.
c) Hujjatning umumiy uzunligini normalizatsiya qilish
d) Soâ€˜zlarning grammatik shaklini aniqlash
183.	Kosinus oâ€˜xshashligi metrikasining asosiy afzalligi nima?
a) Eng tez hisoblash mumkin
#b) Hujjat uzunligiga bogâ€˜liq emas, faqat yoâ€˜nalishni oâ€˜lchaydi.
c) Eng aniq natija beradi
d) Barcha tillarda bir xil ishlaydi
184.	Sparsity (gâ€˜ovaklik) muammosi nima haqida?
a) Hujjatlar juda qisqa boâ€˜lishi
#b) Vektor fazoda elementlarning katta qismi (99%+) nolga teng boâ€˜lishi.
c) Maâ€˜lumotlar bazasi toâ€˜lmasligi
d) Korpusda soâ€˜zlar kam boâ€˜lishi
185.	Word2Vec ning Skip-gram modeli qanday ishlaydi?
a) Kontekst soâ€˜zlardan markaziy soâ€˜zni bashorat qiladi
#b) Markaziy soâ€˜zdan kontekst soâ€˜zlarni bashorat qiladi.
c) Soâ€˜zlarni alifbo tartibida saralaydi
d) Soâ€˜zlarning grammatik shaklini oâ€˜zgartiradi
186.	Yevklid masofasining matn tahlilida asosiy kamchiligi nima?
a) Hisoblash juda sekin
b) Faqat ingliz tili uchun ishlaydi
#c) Hujjat uzunligiga bogâ€˜liq (length bias muammosi).
d) Manfiy qiymatlar bera olmaydi
187.	Rocchio algoritmida har bir sinf qanday ifodalanadi?
a) Eng uzun hujjat orqali
#b) Bitta markaziy vektor (centroid) orqali.
c) Eng qisqa hujjat orqali
d) Tasodifiy tanlangan hujjat orqali
188.	fastText ning Word2Vec dan asosiy farqi nimada?
a) Tezroq ishlaydi
#b) Soâ€˜zni ichki n-grammalarga ajratadi va OOV muammosini hal qiladi.
c) Faqat ingliz tili uchun moâ€˜ljallangan
d) Kamroq xotira talab qiladi
189.	Bias-Variance Tradeoff da â€œHigh Biasâ€ (yuqori tarafkashlik) qanday holatni bildiradi?
a) Model juda murakkab va overfitting
#b) Model juda sodda va underfitting.
c) Model optimal ishlayapti
d) Maâ€˜lumotlarda xato bor
190.	BERT modelining asosiy innovatsiyasi nimada?
a) Eng kichik model hajmi
#b) Har bir soâ€˜z uchun kontekstga qarab turli vektorlar beradi.
c) Faqat oâ€˜zbek tili uchun ishlab chiqilgan
d) Internetga ulanish talab qilmaydi
191.	Naive Bayes algoritmida â€œNaiveâ€ (sodda) taxmin nima haqida?
a) Model oâ€˜qitish jarayoni sodda
#b) Barcha soâ€˜zlar bir-biridan mustaqil deb hisoblanadi.
c) Faqat sodda matnlar uchun ishlatiladi
d) Hisoblash murakkabligi past
192.	SVM (Support Vector Machine) algoritmining asosiy maqsadi nima?
a) Eng koâ€˜p xususiyatlarni topish
b) Eng tez tasniflovchi qurish
#c) Ikki sinf orasida maksimal margin bilan gipertekislik toppish.
d) Barcha maâ€™lumotlarni toâ€˜gâ€˜ri tasniflash
193.	Laplace Smoothing nima uchun ishlatiladi?
a) Modelni tezlashtirish uchun
#b) Nol ehtimollikni oldini olish uchun.
c) Xotira sarfini kamaytirish uchun
d) Aniqlikni oshirish uchun
194.	Soft-Margin SVM da C parametri nimani bildiradi?
a) Model aniqligini
b) Oâ€˜qitish tezligini
#c) Regularizatsiya parametri (jarima koeffitsienti).
d) Support Vectors sonini
195.	Learning to Rank (LTR) ning qaysi yondashuvi butun roâ€˜yxatni birdan optimizatsiya qiladi?
a) Pointwise Approach
b) Pairwise Approach
#c) Listwise Approach.
d) Hybrid Approach
196.	Random Forest algoritmi qanday ishlaydi?
a) Bitta chuqur qaror daraxti yaratadi
#b) Koâ€˜plab mustaqil daraxtlarning ensemble (toâ€˜plami)dan foydalanadi.
c) Faqat eng muhim xususiyatlarni tanlaydi
d) Ketma-ket daraxtlar zanjirini quradi
197.	NDCG (Normalized Discounted Cumulative Gain) metrikasi nima uchun ishlatiladi?
a) Tasnif aniqligini oâ€˜lchash
#b) Ranking natijalarining sifatini baholash.
c) Model tezligini oâ€˜lchash
d) Xotira sarfini aniqlash
198.	RBF (Radial Basis Function) kernel qachon eng yaxshi natija beradi?
a) Katta korpuslar uchun (>100K hujjat)
b) Chiziqli ajratiladigan maâ€™lumotlar uchun
#c) Kichik korpuslar va nochiziqli patternlar uchun.
d) Real-time production sistemalar uchun
199.	ColBERT modelining asosiy afzalligi nimada?
a) Eng arzon model
#b) Cross-Encoder aniqligiga yaqin, lekin Bi-Encoder tezligida.
c) Eng kichik model hajmi
d) Eng tez oâ€˜qitish jarayoni
200.	Decision Tree da Information Gain (IG) nima uchun hisoblanadi?
a) Model aniqligini aniqlash uchun
#b) Eng yaxshi ajratish xususiyatini tanlash uchun.
c) Overfittingni oldini olish uchun
d) Daraxt chuqurligini aniqlash uchun

</div>

<div id="list"></div>

<script>
const raw = document.getElementById("data").innerText.trim();
const questions = raw.split(/\n\s*\n/); // har bir boâ€˜sh qator yangi savol
const list = document.getElementById("list");
const input = document.getElementById("search");

function show(arr, highlight="") {
  list.innerHTML = "";
  arr.forEach(q => {
    const div = document.createElement("div");
    div.className = "question";
    
    if (highlight) {
      const regex = new RegExp(highlight, "gi");
      div.innerHTML = q.replace(regex, m => `<mark>${m}</mark>`);
    } else {
      div.textContent = q;
    }
    list.appendChild(div);
  });

  // Auto-scroll birinchi topilgan savolga
  if (highlight && arr.length > 0) {
    list.firstChild.scrollIntoView({ behavior: "smooth", block: "start" });
  }
}

// Boshlangâ€˜ich holat â€” hammasi chiqadi
show(questions);

input.addEventListener("input", () => {
  const key = input.value.trim().toLowerCase();

  if (key === "") {
    show(questions);
    return;
  }

  const filtered = questions.filter(q =>
    q.toLowerCase().includes(key)
  );

  show(filtered, key);
});
</script>

</body>
</html>